{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망이란?\n",
    "뇌가 신호(정보)를 처리하는 과정 : '뉴런'을 이용한 전달, 뉴런에서 다음 뉴런으로 전달될 때 기준치(역치)에 따라 다음 뉴런으로 전달될지 말지가 결정됨.\n",
    "* 이러한 인류의 신경망 구조를 본따 `Perceptron`이 만들어졌다.\n",
    "* Perceptron이 `deep`해졌을 때 Artificial Neural Network라고 부른다.\n",
    "* 즉, NN은 뇌의 복잡한 구조(`deep`)와 기준치(`Activation`)을 모방하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Recap\n",
    "MNIST를 CNN이 아닌 MLP(Multi-Layer Perceptron)으로 구현."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 987us/step - loss: 0.4856 - accuracy: 0.8846\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2285 - accuracy: 0.9362\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 903us/step - loss: 0.1774 - accuracy: 0.9502\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 869us/step - loss: 0.1465 - accuracy: 0.9584\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 859us/step - loss: 0.1261 - accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 911us/step - loss: 0.1109 - accuracy: 0.9690\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 880us/step - loss: 0.0991 - accuracy: 0.9722\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 871us/step - loss: 0.0890 - accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 886us/step - loss: 0.0808 - accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 913us/step - loss: 0.0742 - accuracy: 0.9795\n",
      "313/313 - 0s - loss: 0.1025 - accuracy: 0.9681\n",
      "test_loss: 0.10253355652093887 \n",
      "test_accuracy: 0.9681000113487244\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "print(x_train.shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Input layer - Hidden layer - Output layer 사이에는 `Matrix`가 존재한다.\n",
    "* 입력값이 100개, Hidden units이 20개라면 matrix는 (`100X20`)\n",
    "* **입력값 = input features**\n",
    "* **Output units = Class의 개수**\n",
    "    * MNIST의 경우 0~9까지의 손글씨를 맞추기 위한 10개의 class를 갖는다. 따라서 Output layer의 노드 개수도 10개여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weight는 random 초기화한다.\n",
    "* Bias는 0으로 초기화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12831986,  0.34757652, -0.81301709,  2.0460106 ,  0.75304647,\n",
       "       -0.03662706,  0.48098521, -0.8799753 ,  0.92093218, -0.52273404,\n",
       "        0.07658515,  0.52664203, -0.88749939, -0.17171376, -0.66168775,\n",
       "       -0.5954174 , -0.36591207, -1.59778276, -0.38993008,  0.05776485,\n",
       "       -0.29032406,  0.03750873, -1.48661119, -1.66072379,  0.01230781,\n",
       "       -1.71820746, -0.54095696,  1.18472006,  1.53210678,  0.69532812,\n",
       "       -0.17996927, -1.89194452,  2.32141671, -1.00209592,  0.80715389,\n",
       "       -1.59161504, -0.53183858, -1.03156617, -0.00655425, -1.85682022,\n",
       "        2.84724928, -0.1623452 , -0.50999526, -0.28819892, -1.15618421,\n",
       "        0.23364065,  0.65463123,  0.43204832, -1.13997936, -1.25071436])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 Hidden layer 출력\n",
    "a1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function\n",
    "활성화 함수는 보통 비선형 함수를 사용합니다. 그리고 이 비선형 함수를 MLP 안에 포함시키면서 모델의 표현력이 좋아지게 됩니다. (정확히는 이 비선형 함수가 포함되지 않으면 한 층을 가진 MLP와 다른 점이 없습니다.)\n",
    "* Activation function : 신호를 다음 노드로 전달할지 말지를 결정하는 기준.\n",
    "* 종류로는 sigmoid, tanh, ReLU가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "* 0 < y < 1\n",
    "* Gradient Vanising 현상 발생\n",
    "    * sigmoid 함수를 미분하면 최댓값이 0.25인 종 모양 함수\n",
    "    * 따라서 네트워크가 깊어질수록 gradient가 0에 수렴한다.\n",
    "* exp 함수를 사용해야 하므로 비용이 크다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30291534 0.44216793 0.49734126 0.90439522 0.61115838 0.60334965\n",
      " 0.6519585  0.64564723 0.6183623  0.55413041 0.63504549 0.38184895\n",
      " 0.54433687 0.20812708 0.50532092 0.35982128 0.3933777  0.38974585\n",
      " 0.20156665 0.73687565 0.21559446 0.66738357 0.38874714 0.23166733\n",
      " 0.29512427 0.2952574  0.59110883 0.49975218 0.46640569 0.55968207\n",
      " 0.25433403 0.11184761 0.69451557 0.2750759  0.77406099 0.22735713\n",
      " 0.34128596 0.60039114 0.18518251 0.10241665 0.90851238 0.59558342\n",
      " 0.55874138 0.34120135 0.59559928 0.30798125 0.37463389 0.6286468\n",
      " 0.28487678 0.48928369]\n"
     ]
    }
   ],
   "source": [
    "# sigmoid : 모든 출력이 0에서 1 사이에 있다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 엘리먼트가 0에서 1사이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh\n",
    "* -1 < y < 1\n",
    "* x의 중심값이 0이므로 sigmoid의 최적화 과정이 느려지는 것을 개선하였다.\n",
    "* sigmoid보다는 낫지만, 여전히 gradient vanising 문제가 존재한다.\n",
    "    * 도함수는 최댓값이 1인 종모양\n",
    "\n",
    "### ReLU(Rectified Linear Unit)\n",
    "```f(x) = max(0,x)```\n",
    "* 학습이 빠르다.\n",
    "* 연산 비용이 크지 않고, 구현이 매우 간단하다.\n",
    "* 값이 0인지 x인지를 가르는 x값(기준치)를 `bias`라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "(10,)\n",
      "[-0.52482879 -0.44454289  0.51597302  0.36153058  0.51744031 -0.5423958\n",
      "  0.02821237 -0.14005742  0.30282657  0.62381208]\n",
      "(5, 50)\n",
      "(5, 10)\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)# z1이 두번째 레이어의 입력 \n",
    "\n",
    "print(W2.shape)\n",
    "print(b2.shape)\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터\n",
    "print(a1.shape)\n",
    "print(a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05048145, 0.05470154, 0.14293755, 0.12248215, 0.14314743,\n",
       "       0.04960239, 0.08776363, 0.0741713 , 0.11549894, 0.15921362])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2) # output layer의 출력(모델의 예측값)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Activation function을 거쳐 신호들은 Output layer로 전달된다. Output layer의 출력을 예측값(predict value)라 하고, 실제 정답과 모델의 예측값 차이를 계산하고, 이 차이를 줄이기 위해 각 파라미터들을 조정(update)하는 것이 딥러닝의 전체적인 학습 흐름이다.\n",
    "* loss function(cost function) : 정답과 예측값의 차이를 구하는데 사용되는 함수.\n",
    "    * MSE(Mean Square Error)\n",
    "    * Cross Entropy : 두 확률분포 사이의 유사도가 클수록 작아진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05048145 0.05470154 0.14293755 0.12248215 0.14314743 0.04960239\n",
      " 0.08776363 0.0741713  0.11549894 0.15921362]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5531880175808794"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "앞서 구한 오차(cost function의 크기)를 줄이기 위한 방법.\n",
    "* 파라미터 W의 변화에 따른 Loss의 변화량을 구하고, 변화량의 기울기가 커지는 방향의 반대 방향으로 파라미터를 조정한다.\n",
    "* learning rate\n",
    "* parameter 초기화(가중치 초기화)를 어떻게 하는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01009629,  0.01094031,  0.02858751,  0.02449643,  0.02862949,\n",
       "        -0.19007952,  0.01755273,  0.01483426,  0.02309979,  0.03184272],\n",
       "       [-0.18808169,  0.01078796,  0.02309842,  0.02561775,  0.03444927,\n",
       "         0.01311046,  0.01704825,  0.01725052,  0.02182259,  0.02489647],\n",
       "       [ 0.0122521 ,  0.01207237,  0.0270282 ,  0.02440747, -0.17451958,\n",
       "         0.00978173,  0.01527889,  0.01237196,  0.03185732,  0.02946954],\n",
       "       [ 0.01136235, -0.18930368,  0.02344259,  0.02427268,  0.02640512,\n",
       "         0.01246232,  0.02045353,  0.01299459,  0.0237139 ,  0.03419661],\n",
       "       [ 0.01202621,  0.01018632,  0.0263293 ,  0.0288923 ,  0.0286584 ,\n",
       "         0.01003091,  0.01818529,  0.01425135,  0.02307482, -0.1716349 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num # dy = aLoss/ay \n",
    "dy # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0799581 , -0.06475592,  0.05796333,  0.05862593,  0.01493084,\n",
       "        -0.06561424,  0.04064943,  0.03315821,  0.05425917, -0.04925866],\n",
       "       [-0.03051291, -0.0880585 ,  0.06828091,  0.06866656, -0.05598372,\n",
       "        -0.03149511,  0.04712121,  0.03693435,  0.06691783, -0.08187063],\n",
       "       [-0.03205152, -0.02401525,  0.02942202,  0.03053923, -0.00852774,\n",
       "        -0.00028206,  0.02049704,  0.01655235,  0.02830704, -0.06044111],\n",
       "       [-0.10603798, -0.03740176,  0.07387233,  0.0726809 , -0.05884223,\n",
       "        -0.09520884,  0.0494635 ,  0.04138683,  0.07148065, -0.0113934 ],\n",
       "       [-0.09932118, -0.06983181,  0.0958936 ,  0.0940193 , -0.05113742,\n",
       "        -0.14813035,  0.06463006,  0.05305838,  0.09148579, -0.03066637],\n",
       "       [-0.04592732, -0.05257281,  0.06690448,  0.0656894 , -0.08515763,\n",
       "        -0.0625648 ,  0.04469118,  0.03607025,  0.0660754 , -0.03320815],\n",
       "       [-0.03479075, -0.08303419,  0.05560139,  0.05478303,  0.00814077,\n",
       "        -0.09701377,  0.03877094,  0.0306772 ,  0.05186898, -0.0250036 ],\n",
       "       [-0.00145678, -0.05875691,  0.05612428,  0.05523358, -0.11113574,\n",
       "        -0.01576519,  0.037371  ,  0.02910109,  0.05727875, -0.04799406],\n",
       "       [-0.08530644, -0.05709643,  0.06140824,  0.0606193 ,  0.00313288,\n",
       "        -0.1066156 ,  0.04221518,  0.03485938,  0.05743075, -0.01064727],\n",
       "       [-0.05273519, -0.06972428,  0.0415436 ,  0.04048173, -0.02641115,\n",
       "        -0.05876156,  0.02887172,  0.02324347,  0.04058771,  0.03290394],\n",
       "       [-0.05410784, -0.06720467,  0.06223043,  0.06142643, -0.03585427,\n",
       "        -0.07693285,  0.04252121,  0.0342596 ,  0.05992568, -0.02626371],\n",
       "       [-0.07781644, -0.07196269,  0.05005239,  0.05209449,  0.02848975,\n",
       "        -0.02113127,  0.03612291,  0.02915443,  0.04693756, -0.07194114],\n",
       "       [-0.03496075, -0.03654918,  0.05787758,  0.05856642, -0.04809245,\n",
       "        -0.02439178,  0.03919007,  0.03146249,  0.05625097, -0.09935336],\n",
       "       [-0.08366128, -0.07026491,  0.04035371,  0.04174543,  0.02333303,\n",
       "        -0.02152266,  0.02943942,  0.0240005 ,  0.03818145, -0.02160467],\n",
       "       [-0.09367746, -0.05682376,  0.06768289,  0.06767299,  0.01947258,\n",
       "        -0.10575424,  0.04678732,  0.03862105,  0.0626757 , -0.04665707],\n",
       "       [-0.01497465, -0.05645983,  0.02722471,  0.02683184, -0.02310641,\n",
       "        -0.02297906,  0.01912926,  0.01478004,  0.02697373,  0.00258036],\n",
       "       [-0.06991496, -0.07029577,  0.0538188 ,  0.0539487 , -0.01919163,\n",
       "        -0.04781076,  0.03753701,  0.03038058,  0.05196517, -0.02043714],\n",
       "       [-0.0094403 , -0.07823476,  0.04166727,  0.04191893, -0.01297937,\n",
       "        -0.02919144,  0.02947234,  0.0225619 ,  0.04018269, -0.04595727],\n",
       "       [-0.08558734, -0.14895296,  0.07375179,  0.07384664, -0.00126755,\n",
       "        -0.07469611,  0.05282116,  0.0417194 ,  0.0708522 , -0.00248723],\n",
       "       [-0.09125158, -0.05731849,  0.07315603,  0.07288814, -0.02027053,\n",
       "        -0.09167888,  0.05000208,  0.04112435,  0.06947684, -0.04612796],\n",
       "       [-0.09964971, -0.07870914,  0.07617945,  0.07594628,  0.00460955,\n",
       "        -0.10904776,  0.0527702 ,  0.04319899,  0.07152276, -0.03682061],\n",
       "       [-0.0917938 , -0.11256893,  0.08104231,  0.07922584, -0.03458129,\n",
       "        -0.12575004,  0.05593056,  0.0451987 ,  0.07789768,  0.02539896],\n",
       "       [-0.07881087, -0.08504757,  0.08838897,  0.08658508, -0.05044313,\n",
       "        -0.13161301,  0.05995014,  0.04862022,  0.08471684, -0.02234667],\n",
       "       [-0.06473902, -0.1138126 ,  0.07325264,  0.07320785, -0.01178745,\n",
       "        -0.07878861,  0.05142099,  0.04078075,  0.07000432, -0.03953888],\n",
       "       [-0.13647931, -0.07508119,  0.0961667 ,  0.09576432, -0.01032502,\n",
       "        -0.13414186,  0.06592303,  0.0545791 ,  0.09068961, -0.04709537],\n",
       "       [-0.0683742 , -0.08809669,  0.07197218,  0.0704621 , -0.0184859 ,\n",
       "        -0.12099038,  0.04945724,  0.03991923,  0.068273  , -0.00413659],\n",
       "       [-0.09393086, -0.09954831,  0.06753628,  0.06870071,  0.04437098,\n",
       "        -0.07962157,  0.04828706,  0.03897631,  0.06249594, -0.05726654],\n",
       "       [-0.13307125, -0.0577131 ,  0.08151502,  0.0809958 , -0.02241535,\n",
       "        -0.10965723,  0.0556543 ,  0.04652276,  0.07753858, -0.01936952],\n",
       "       [-0.11159722, -0.04241059,  0.0653241 ,  0.06596569, -0.01392187,\n",
       "        -0.06053541,  0.04490307,  0.03752938,  0.06224557, -0.04750272],\n",
       "       [-0.06233086, -0.09910198,  0.06721074,  0.06681197,  0.00596647,\n",
       "        -0.09680511,  0.04709172,  0.03758002,  0.06324465, -0.02966761],\n",
       "       [-0.11089252, -0.03140094,  0.06531929,  0.06404505, -0.01459858,\n",
       "        -0.11920337,  0.04401872,  0.03728741,  0.06147662,  0.00394832],\n",
       "       [-0.03584846, -0.05291472,  0.04366973,  0.04350888, -0.00313935,\n",
       "        -0.05748139,  0.03027515,  0.02423233,  0.04120206, -0.03350423],\n",
       "       [-0.112398  , -0.07566829,  0.06762143,  0.06787333,  0.01355427,\n",
       "        -0.08859954,  0.04732166,  0.03904568,  0.06351893, -0.02226947],\n",
       "       [-0.11405022, -0.05935795,  0.07012437,  0.07028396, -0.01490087,\n",
       "        -0.07746755,  0.04833545,  0.04013216,  0.06685357, -0.02995292],\n",
       "       [-0.09219183, -0.08767003,  0.08850649,  0.08710874, -0.02666022,\n",
       "        -0.13699243,  0.06048119,  0.04924448,  0.08398621, -0.0258126 ],\n",
       "       [-0.06085389, -0.035475  ,  0.03929152,  0.03938331, -0.02358197,\n",
       "        -0.03129746,  0.02699605,  0.02229129,  0.03820268, -0.01495652],\n",
       "       [-0.08635499, -0.12407973,  0.09547131,  0.09498773, -0.0512881 ,\n",
       "        -0.09366835,  0.06601927,  0.05279299,  0.09240701, -0.04628714],\n",
       "       [-0.02256323, -0.04168609,  0.04357064,  0.04209995,  0.00694188,\n",
       "        -0.10657715,  0.02954291,  0.02379719,  0.03988619, -0.0150123 ],\n",
       "       [ 0.00571306, -0.10974003,  0.05416193,  0.05316874, -0.09814473,\n",
       "        -0.01362418,  0.03732381,  0.02810363,  0.05570567, -0.01266789],\n",
       "       [-0.04974602, -0.09823575,  0.05136865,  0.05075664,  0.01217486,\n",
       "        -0.08346291,  0.03650224,  0.02885729,  0.04831341,  0.0034716 ],\n",
       "       [-0.01966057, -0.11201796,  0.06237899,  0.06294738, -0.03637304,\n",
       "        -0.0262793 ,  0.04394954,  0.03376974,  0.06099069, -0.06970546],\n",
       "       [-0.05132912, -0.07045885,  0.07140204,  0.06909935, -0.05612649,\n",
       "        -0.11942025,  0.04801405,  0.03877663,  0.06882576,  0.0012169 ],\n",
       "       [-0.04506226, -0.05224086,  0.04424995,  0.04378559, -0.03279273,\n",
       "        -0.04480736,  0.03034785,  0.02447405,  0.04314281, -0.01109705],\n",
       "       [-0.04317058, -0.10827769,  0.06171475,  0.0605125 ,  0.00031917,\n",
       "        -0.10582343,  0.04327426,  0.03409057,  0.05824402, -0.00088357],\n",
       "       [-0.03681628, -0.09236982,  0.07244315,  0.07203502,  0.00151436,\n",
       "        -0.1039803 ,  0.05023134,  0.03972238,  0.06784219, -0.07062205],\n",
       "       [-0.05207373, -0.03777799,  0.04453298,  0.04373822, -0.06849996,\n",
       "        -0.03117846,  0.02982644,  0.02441964,  0.04481928,  0.00219359],\n",
       "       [-0.13574759, -0.06118077,  0.0782336 ,  0.07763116, -0.01383582,\n",
       "        -0.11261976,  0.0536212 ,  0.04490599,  0.07420307, -0.0052111 ],\n",
       "       [-0.05248456, -0.09262571,  0.081342  ,  0.07932366, -0.08355025,\n",
       "        -0.10047094,  0.05499403,  0.04395735,  0.07970396, -0.01018953],\n",
       "       [-0.10502743, -0.08114171,  0.06893521,  0.06980155, -0.03536324,\n",
       "        -0.03419868,  0.04807871,  0.0392337 ,  0.06728359, -0.03760172],\n",
       "       [-0.00136429, -0.08302966,  0.04447278,  0.04281121, -0.06314841,\n",
       "        -0.05097678,  0.03038225,  0.0232647 ,  0.04457217,  0.01301603]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "Gradient descent로 구한 기울기를 어떻게 Input layer로 전달하여 파라미터를 조정(update)할 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11463054 0.09170069 0.13077456 0.14760841 0.06674502 0.05200574\n",
      "  0.12955146 0.09364097 0.08071439 0.09262822]\n",
      " [0.1239482  0.10251724 0.104672   0.13336732 0.07814976 0.05839971\n",
      "  0.1632073  0.07743007 0.06951684 0.08879158]\n",
      " [0.10644494 0.09244442 0.10417061 0.13198127 0.06393785 0.06586027\n",
      "  0.13572441 0.10823544 0.09101706 0.10018372]\n",
      " [0.10352318 0.10985384 0.11111911 0.14674458 0.07169492 0.06643063\n",
      "  0.13309173 0.09122061 0.07689639 0.08942499]\n",
      " [0.12456173 0.09529779 0.0826805  0.13808148 0.07024826 0.04940456\n",
      "  0.15837034 0.10701631 0.08104583 0.09329319]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.4749498194725765\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_ont_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Parameter 업데이트에 따라 점점 Loss가 줄어드는지(점점 정확한 추론을 하는지) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_ont_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        #print(y_hat)\n",
    "        #print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Loss:  2.220537379545103\n",
      "---------\n",
      "Loss:  2.0669041564253834\n",
      "---------\n",
      "Loss:  1.9433594927873217\n",
      "---------\n",
      "Loss:  1.8416144508680652\n",
      "---------\n",
      "Loss:  1.755732849112722\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 예측과 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14688295, 0.13141848, 0.03871126, 0.04784663, 0.12237008,\n",
       "       0.20813865, 0.06576103, 0.0535397 , 0.04032806, 0.14500315])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100가지 train example을 가지고 추론\n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "   # t = np.argmax(t, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14688295 0.13141848 0.03871126 0.04784663 0.12237008 0.20813865\n",
      " 0.06576103 0.0535397  0.04032806 0.14500315]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.07\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_ont_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 데이터셋에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.3022694078249204\n",
      "train acc, test acc | 0.12318333333333334, 0.1276\n",
      "Loss:  0.8408604072788957\n",
      "train acc, test acc | 0.7795333333333333, 0.7876\n",
      "Loss:  0.4812913531638655\n",
      "train acc, test acc | 0.877, 0.881\n",
      "Loss:  0.3950979391261163\n",
      "train acc, test acc | 0.8982166666666667, 0.9002\n",
      "Loss:  0.3256717561976253\n",
      "train acc, test acc | 0.9064166666666666, 0.9088\n",
      "Loss:  0.31560265592061737\n",
      "train acc, test acc | 0.9130666666666667, 0.9154\n",
      "Loss:  0.21562401508609486\n",
      "train acc, test acc | 0.9179, 0.9208\n",
      "Loss:  0.23268433502655378\n",
      "train acc, test acc | 0.9234666666666667, 0.9236\n",
      "Loss:  0.2647695324778799\n",
      "train acc, test acc | 0.9274666666666667, 0.9288\n",
      "Loss:  0.18977848194727445\n",
      "train acc, test acc | 0.9312833333333334, 0.9289\n",
      "Loss:  0.3957356110034976\n",
      "train acc, test acc | 0.9341666666666667, 0.9347\n",
      "Loss:  0.2600388744951183\n",
      "train acc, test acc | 0.9368666666666666, 0.9368\n",
      "Loss:  0.15548599243614947\n",
      "train acc, test acc | 0.93955, 0.939\n",
      "Loss:  0.27416209294020794\n",
      "train acc, test acc | 0.9412333333333334, 0.9404\n",
      "Loss:  0.2097405110106808\n",
      "train acc, test acc | 0.94325, 0.9429\n",
      "Loss:  0.12502182500896195\n",
      "train acc, test acc | 0.9451666666666667, 0.9434\n",
      "Loss:  0.1692445551416844\n",
      "train acc, test acc | 0.94705, 0.9457\n",
      "Loss:  0.262311308315193\n",
      "train acc, test acc | 0.9479166666666666, 0.9473\n",
      "Loss:  0.13425456063747837\n",
      "train acc, test acc | 0.9493333333333334, 0.9485\n",
      "Loss:  0.1551362536383217\n",
      "train acc, test acc | 0.9511333333333334, 0.9492\n",
      "Loss:  0.14668742334551665\n",
      "train acc, test acc | 0.9527, 0.9502\n",
      "Loss:  0.217989480439319\n",
      "train acc, test acc | 0.9537166666666667, 0.9524\n",
      "Loss:  0.14182723931120825\n",
      "train acc, test acc | 0.9547333333333333, 0.9531\n",
      "Loss:  0.15919683974757465\n",
      "train acc, test acc | 0.9556333333333333, 0.9536\n",
      "Loss:  0.14678110901701596\n",
      "train acc, test acc | 0.9567833333333333, 0.9543\n",
      "Loss:  0.19812055724207847\n",
      "train acc, test acc | 0.958, 0.9554\n",
      "Loss:  0.13117027319226282\n",
      "train acc, test acc | 0.9591166666666666, 0.9557\n",
      "Loss:  0.1369270124900069\n",
      "train acc, test acc | 0.9596, 0.9568\n",
      "Loss:  0.16239948371451174\n",
      "train acc, test acc | 0.96085, 0.957\n",
      "Loss:  0.11683078449234145\n",
      "train acc, test acc | 0.9615666666666667, 0.9574\n",
      "Loss:  0.11298164336292692\n",
      "train acc, test acc | 0.9624, 0.958\n",
      "Loss:  0.10751241829144703\n",
      "train acc, test acc | 0.96315, 0.9579\n",
      "Loss:  0.09189814521058265\n",
      "train acc, test acc | 0.96415, 0.96\n",
      "Loss:  0.07828913552394341\n",
      "train acc, test acc | 0.9649, 0.9598\n",
      "Loss:  0.051987469422897344\n",
      "train acc, test acc | 0.9657, 0.9597\n",
      "Loss:  0.07724521012286702\n",
      "train acc, test acc | 0.9662, 0.9599\n",
      "Loss:  0.19404009316904614\n",
      "train acc, test acc | 0.96715, 0.961\n",
      "Loss:  0.21067701832399466\n",
      "train acc, test acc | 0.96655, 0.9612\n",
      "Loss:  0.18611968101627405\n",
      "train acc, test acc | 0.9681333333333333, 0.961\n",
      "Loss:  0.10358516909405557\n",
      "train acc, test acc | 0.9685333333333334, 0.9611\n",
      "Loss:  0.140676421584192\n",
      "train acc, test acc | 0.9693, 0.9618\n",
      "Loss:  0.06167447238175204\n",
      "train acc, test acc | 0.9695666666666667, 0.9625\n",
      "Loss:  0.08774971873120829\n",
      "train acc, test acc | 0.9700166666666666, 0.962\n",
      "Loss:  0.11574581186225309\n",
      "train acc, test acc | 0.9705333333333334, 0.9631\n",
      "Loss:  0.09426034595053556\n",
      "train acc, test acc | 0.9709833333333333, 0.9634\n",
      "Loss:  0.14012188431059053\n",
      "train acc, test acc | 0.9714, 0.9631\n",
      "Loss:  0.07111700829931196\n",
      "train acc, test acc | 0.9717333333333333, 0.9637\n",
      "Loss:  0.04049417211742925\n",
      "train acc, test acc | 0.97275, 0.9645\n",
      "Loss:  0.057182942928594\n",
      "train acc, test acc | 0.97265, 0.9644\n",
      "Loss:  0.13751620874311782\n",
      "train acc, test acc | 0.9733333333333334, 0.9647\n",
      "Loss:  0.0773217787320894\n",
      "train acc, test acc | 0.97335, 0.9651\n",
      "Loss:  0.16171207718686575\n",
      "train acc, test acc | 0.9734333333333334, 0.9659\n",
      "Loss:  0.0577085062451\n",
      "train acc, test acc | 0.9740666666666666, 0.9656\n",
      "Loss:  0.06519143499749623\n",
      "train acc, test acc | 0.97465, 0.9661\n",
      "Loss:  0.05648810751439157\n",
      "train acc, test acc | 0.975, 0.9667\n",
      "Loss:  0.057327227417660984\n",
      "train acc, test acc | 0.9754666666666667, 0.9661\n",
      "Loss:  0.11526382624445333\n",
      "train acc, test acc | 0.9757, 0.9664\n",
      "Loss:  0.07253024132272898\n",
      "train acc, test acc | 0.9759, 0.9663\n",
      "Loss:  0.09588678025205848\n",
      "train acc, test acc | 0.97655, 0.9674\n",
      "Loss:  0.10613052317304686\n",
      "train acc, test acc | 0.9763166666666667, 0.9675\n",
      "Loss:  0.038787160231969084\n",
      "train acc, test acc | 0.9769166666666667, 0.9676\n",
      "Loss:  0.037040642676847944\n",
      "train acc, test acc | 0.9773833333333334, 0.968\n",
      "Loss:  0.06216300556971968\n",
      "train acc, test acc | 0.9773666666666667, 0.968\n",
      "Loss:  0.07210534299342725\n",
      "train acc, test acc | 0.9777, 0.9672\n",
      "Loss:  0.043862881061551\n",
      "train acc, test acc | 0.9782833333333333, 0.9682\n",
      "Loss:  0.052240997258653415\n",
      "train acc, test acc | 0.97825, 0.9684\n",
      "Loss:  0.04880712769526901\n",
      "train acc, test acc | 0.9784166666666667, 0.9681\n",
      "Loss:  0.094693748966711\n",
      "train acc, test acc | 0.9788333333333333, 0.9691\n",
      "Loss:  0.09730716620756967\n",
      "train acc, test acc | 0.9792166666666666, 0.9695\n",
      "Loss:  0.03784613600641238\n",
      "train acc, test acc | 0.9796, 0.9685\n",
      "Loss:  0.13095635956084548\n",
      "train acc, test acc | 0.97995, 0.9692\n",
      "Loss:  0.08628824214279313\n",
      "train acc, test acc | 0.98005, 0.9693\n",
      "Loss:  0.02943450672051426\n",
      "train acc, test acc | 0.98045, 0.9691\n",
      "Loss:  0.05349535136009392\n",
      "train acc, test acc | 0.9805166666666667, 0.9694\n",
      "Loss:  0.09242134172361938\n",
      "train acc, test acc | 0.9808833333333333, 0.97\n",
      "Loss:  0.15232728042437815\n",
      "train acc, test acc | 0.9811833333333333, 0.9706\n",
      "Loss:  0.09520501315724146\n",
      "train acc, test acc | 0.98105, 0.9705\n",
      "Loss:  0.06082934831844467\n",
      "train acc, test acc | 0.9816, 0.9703\n",
      "Loss:  0.04649555780729481\n",
      "train acc, test acc | 0.9816666666666667, 0.9706\n",
      "Loss:  0.06776331701886901\n",
      "train acc, test acc | 0.9818833333333333, 0.9704\n",
      "Loss:  0.09018048536860163\n",
      "train acc, test acc | 0.9824, 0.9715\n",
      "Loss:  0.06243698513839721\n",
      "train acc, test acc | 0.9824, 0.9708\n",
      "Loss:  0.12142528626083954\n",
      "train acc, test acc | 0.9825333333333334, 0.9715\n",
      "Loss:  0.10305250641518539\n",
      "train acc, test acc | 0.9827, 0.9713\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
